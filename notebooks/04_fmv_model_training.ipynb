{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ag IQ FMV Model Training\n",
    "\n",
    "This notebook trains the Fair Market Value (FMV) prediction model using LightGBM gradient boosting.\n",
    "\n",
    "**Goal**: Build a high-accuracy valuation model achieving:\n",
    "- **MAPE < 10%** (Mean Absolute Percentage Error)\n",
    "- **R² > 0.85** (Variance explained)\n",
    "- **RMSE < $15,000** (Root Mean Squared Error)\n",
    "\n",
    "**Approach**:\n",
    "- Time-based train/val/test splits (70/15/15)\n",
    "- LightGBM with early stopping\n",
    "- Feature importance analysis\n",
    "- Comprehensive performance evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: Setup\n",
    "# =============================================================================\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "print(\"Setup complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/processed/training_data.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# CELL 2: Load Processed Data\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading processed data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m training_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../data/processed/training_data.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(training_df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m records\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDate range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_df[\u001b[33m'\u001b[39m\u001b[33msold_date\u001b[39m\u001b[33m'\u001b[39m].min().date()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_df[\u001b[33m'\u001b[39m\u001b[33msold_date\u001b[39m\u001b[33m'\u001b[39m].max().date()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AssetManager/ag_iq_ml/venv/lib/python3.13/site-packages/pandas/io/parquet.py:669\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    667\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AssetManager/ag_iq_ml/venv/lib/python3.13/site-packages/pandas/io/parquet.py:258\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    257\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    265\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    266\u001b[39m         path_or_handle,\n\u001b[32m    267\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m         **kwargs,\n\u001b[32m    271\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AssetManager/ag_iq_ml/venv/lib/python3.13/site-packages/pandas/io/parquet.py:141\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    131\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AssetManager/ag_iq_ml/venv/lib/python3.13/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/processed/training_data.parquet'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: Load Processed Data\n",
    "# =============================================================================\n",
    "print(\"Loading processed data...\")\n",
    "training_df = pd.read_parquet('../data/processed/training_data.parquet')\n",
    "\n",
    "print(f\"Loaded: {len(training_df):,} records\")\n",
    "print(f\"Date range: {training_df['sold_date'].min().date()} to {training_df['sold_date'].max().date()}\")\n",
    "print(f\"Price range: ${training_df['price'].min():,.0f} to ${training_df['price'].max():,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: Initialize and Train Model\n",
    "# =============================================================================\n",
    "from src.models.fmv import FMVModel\n",
    "from src.features.pipeline import FeaturePipeline\n",
    "\n",
    "# Initialize model\n",
    "model = FMVModel()\n",
    "\n",
    "# Train model\n",
    "# This will:\n",
    "# - Create time-based splits (70% train, 15% val, 15% test)\n",
    "# - Fit feature pipeline on training data\n",
    "# - Train LightGBM with early stopping\n",
    "# - Evaluate on validation and test sets\n",
    "metrics = model.train(training_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: Detailed Performance Analysis\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nModel trained at: {model.metadata['trained_at']}\")\n",
    "print(f\"Best iteration: {model.metadata['best_iteration']}\")\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Training:   {model.metadata['n_train']:,} records\")\n",
    "print(f\"  Validation: {model.metadata['n_val']:,} records\")\n",
    "print(f\"  Test:       {model.metadata['n_test']:,} records\")\n",
    "\n",
    "print(f\"\\n--- Validation Set Performance ---\")\n",
    "print(f\"  RMSE:  ${metrics['val_rmse']:,.0f}\")\n",
    "print(f\"  MAPE:  {metrics['val_mape']:.2f}%\")\n",
    "print(f\"  R²:    {metrics['val_r2']:.4f}\")\n",
    "\n",
    "print(f\"\\n--- Test Set Performance ---\")\n",
    "print(f\"  RMSE:  ${metrics['test_rmse']:,.0f}\")\n",
    "print(f\"  MAPE:  {metrics['test_mape']:.2f}%\")\n",
    "print(f\"  R²:    {metrics['test_r2']:.4f}\")\n",
    "\n",
    "# Check if we met our goals\n",
    "print(f\"\\n--- Goal Achievement ---\")\n",
    "print(f\"  MAPE < 10%:      {'✓ YES' if metrics['test_mape'] < 10 else '✗ NO'} ({metrics['test_mape']:.2f}%)\")\n",
    "print(f\"  R² > 0.85:       {'✓ YES' if metrics['test_r2'] > 0.85 else '✗ NO'} ({metrics['test_r2']:.4f})\")\n",
    "print(f\"  RMSE < $15,000:  {'✓ YES' if metrics['test_rmse'] < 15000 else '✗ NO'} (${metrics['test_rmse']:,.0f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: Feature Importance Analysis\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get feature importance\n",
    "importance_df = model.feature_importance(importance_type='gain')\n",
    "\n",
    "print(f\"\\nTop 20 Most Important Features:\")\n",
    "print(importance_df.head(20).to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_features = importance_df.head(20)\n",
    "ax.barh(range(len(top_features)), top_features['importance'])\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['feature'])\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Importance (Gain)')\n",
    "ax.set_title('Top 20 Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: Prediction Analysis on Test Set\n",
    "# =============================================================================\n",
    "# Get test set predictions\n",
    "test_start_idx = int(len(training_df) * 0.85)\n",
    "test_df = training_df.iloc[test_start_idx:].copy()\n",
    "\n",
    "test_predictions = model.predict(test_df)\n",
    "test_df['predicted_price'] = test_predictions\n",
    "test_df['error'] = test_df['price'] - test_df['predicted_price']\n",
    "test_df['abs_error'] = test_df['error'].abs()\n",
    "test_df['pct_error'] = (test_df['error'] / test_df['price'] * 100).abs()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PREDICTION ANALYSIS (Test Set)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nPrediction Statistics:\")\n",
    "print(f\"  Mean actual price:     ${test_df['price'].mean():,.0f}\")\n",
    "print(f\"  Mean predicted price:  ${test_df['predicted_price'].mean():,.0f}\")\n",
    "print(f\"  Mean absolute error:   ${test_df['abs_error'].mean():,.0f}\")\n",
    "print(f\"  Median absolute error: ${test_df['abs_error'].median():,.0f}\")\n",
    "print(f\"  Mean % error:          {test_df['pct_error'].mean():.2f}%\")\n",
    "print(f\"  Median % error:        {test_df['pct_error'].median():.2f}%\")\n",
    "\n",
    "print(f\"\\nError Distribution:\")\n",
    "print(f\"  Within ±5%:   {(test_df['pct_error'] <= 5).sum():,} ({(test_df['pct_error'] <= 5).mean()*100:.1f}%)\")\n",
    "print(f\"  Within ±10%:  {(test_df['pct_error'] <= 10).sum():,} ({(test_df['pct_error'] <= 10).mean()*100:.1f}%)\")\n",
    "print(f\"  Within ±20%:  {(test_df['pct_error'] <= 20).sum():,} ({(test_df['pct_error'] <= 20).mean()*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: Visualize Predictions\n",
    "# =============================================================================\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Actual vs Predicted scatter\n",
    "sample = test_df.sample(min(5000, len(test_df)))\n",
    "axes[0, 0].scatter(sample['price'], sample['predicted_price'], alpha=0.3, s=1)\n",
    "axes[0, 0].plot([sample['price'].min(), sample['price'].max()], \n",
    "                [sample['price'].min(), sample['price'].max()], \n",
    "                'r--', linewidth=2, label='Perfect prediction')\n",
    "axes[0, 0].set_xlabel('Actual Price ($)')\n",
    "axes[0, 0].set_ylabel('Predicted Price ($)')\n",
    "axes[0, 0].set_title('Actual vs Predicted Prices')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Residual plot\n",
    "axes[0, 1].scatter(sample['predicted_price'], sample['error'], alpha=0.3, s=1)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Predicted Price ($)')\n",
    "axes[0, 1].set_ylabel('Error (Actual - Predicted) ($)')\n",
    "axes[0, 1].set_title('Residual Plot')\n",
    "\n",
    "# Error distribution\n",
    "axes[1, 0].hist(test_df['pct_error'], bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(test_df['pct_error'].median(), color='red', linestyle='--',\n",
    "                   label=f\"Median: {test_df['pct_error'].median():.2f}%\")\n",
    "axes[1, 0].set_xlabel('Absolute Percentage Error (%)')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_title('Error Distribution')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_xlim(0, 50)  # Focus on 0-50% errors\n",
    "\n",
    "# Cumulative error distribution\n",
    "sorted_errors = np.sort(test_df['pct_error'])\n",
    "cumulative = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors) * 100\n",
    "axes[1, 1].plot(sorted_errors, cumulative)\n",
    "axes[1, 1].axvline(10, color='red', linestyle='--', label='10% threshold')\n",
    "axes[1, 1].set_xlabel('Absolute Percentage Error (%)')\n",
    "axes[1, 1].set_ylabel('Cumulative Percentage of Predictions')\n",
    "axes[1, 1].set_title('Cumulative Error Distribution')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_xlim(0, 30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: Save Trained Model\n",
    "# =============================================================================\n",
    "model_path = Path('../models/fmv_model')\n",
    "model.save(str(model_path))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL TRAINING COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n✓ Model saved to: {model_path}\")\n",
    "print(f\"  - model.lgb (LightGBM model)\")\n",
    "print(f\"  - pipeline.joblib (Feature pipeline)\")\n",
    "print(f\"  - metadata.json (Training info & metrics)\")\n",
    "\n",
    "print(f\"\\nFinal Test Set Performance:\")\n",
    "print(f\"  MAPE:  {metrics['test_mape']:.2f}% {'✓ GOAL MET' if metrics['test_mape'] < 10 else '✗ Below target'}\")\n",
    "print(f\"  R²:    {metrics['test_r2']:.4f} {'✓ GOAL MET' if metrics['test_r2'] > 0.85 else '✗ Below target'}\")\n",
    "print(f\"  RMSE:  ${metrics['test_rmse']:,.0f} {'✓ GOAL MET' if metrics['test_rmse'] < 15000 else '✗ Below target'}\")\n",
    "\n",
    "print(f\"\\nNext steps:\")\n",
    "print(\"  - Phase 5: Train Future FMV model (forward-looking predictions)\")\n",
    "print(\"  - Phase 6: Build Streamlit interface for interactive predictions\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
